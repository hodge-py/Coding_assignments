{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-05T02:44:07.344742Z",
     "start_time": "2024-12-05T02:44:06.751410Z"
    }
   },
   "source": [
    "from pyspark.sql import SparkSession # import spark sessions\n",
    "from pyspark.sql.types import IntegerType\n",
    "from datetime import datetime, date\n",
    "import pandas as pd\n",
    "from pyspark.sql import Row\n",
    "import os, sys\n",
    "os.environ['PYSPARK_PYTHON'] = sys.executable # needed for spark to work with python, grabs the venv python executable\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-05T02:49:40.042557Z",
     "start_time": "2024-12-05T02:49:39.742004Z"
    }
   },
   "cell_type": "code",
   "source": [
    "spark = SparkSession.builder.appName(\"homework\").getOrCreate() # creates the app to use later for sql and to read the\n",
    "rdd2 = spark.read.option(\"delimiter\", \",\").option(\"header\", True).csv(\"departuredelays.csv\") # read the csv file with headers enabled\n",
    "rdd2.show()"
   ],
   "id": "5b4b5e9edd69660c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+--------+------+-----------+\n",
      "|    date|delay|distance|origin|destination|\n",
      "+--------+-----+--------+------+-----------+\n",
      "|01011245|    6|     602|   ABE|        ATL|\n",
      "|01020600|   -8|     369|   ABE|        DTW|\n",
      "|01021245|   -2|     602|   ABE|        ATL|\n",
      "|01020605|   -4|     602|   ABE|        ATL|\n",
      "|01031245|   -4|     602|   ABE|        ATL|\n",
      "|01030605|    0|     602|   ABE|        ATL|\n",
      "|01041243|   10|     602|   ABE|        ATL|\n",
      "|01040605|   28|     602|   ABE|        ATL|\n",
      "|01051245|   88|     602|   ABE|        ATL|\n",
      "|01050605|    9|     602|   ABE|        ATL|\n",
      "|01061215|   -6|     602|   ABE|        ATL|\n",
      "|01061725|   69|     602|   ABE|        ATL|\n",
      "|01061230|    0|     369|   ABE|        DTW|\n",
      "|01060625|   -3|     602|   ABE|        ATL|\n",
      "|01070600|    0|     369|   ABE|        DTW|\n",
      "|01071725|    0|     602|   ABE|        ATL|\n",
      "|01071230|    0|     369|   ABE|        DTW|\n",
      "|01070625|    0|     602|   ABE|        ATL|\n",
      "|01071219|    0|     569|   ABE|        ORD|\n",
      "|01080600|    0|     369|   ABE|        DTW|\n",
      "+--------+-----+--------+------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-05T02:52:13.857692Z",
     "start_time": "2024-12-05T02:52:13.611016Z"
    }
   },
   "cell_type": "code",
   "source": [
    "rddTxt = spark.read.option(\"delimiter\", \"\\t\").option(\"header\", True).csv(\"airport-codes-na.txt\")\n",
    "rddTxt.show()"
   ],
   "id": "6d3c147bf77fdbcd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+-------+----+\n",
      "|       City|State|Country|IATA|\n",
      "+-----------+-----+-------+----+\n",
      "| Abbotsford|   BC| Canada| YXX|\n",
      "|   Aberdeen|   SD|    USA| ABR|\n",
      "|    Abilene|   TX|    USA| ABI|\n",
      "|      Akron|   OH|    USA| CAK|\n",
      "|    Alamosa|   CO|    USA| ALS|\n",
      "|     Albany|   GA|    USA| ABY|\n",
      "|     Albany|   NY|    USA| ALB|\n",
      "|Albuquerque|   NM|    USA| ABQ|\n",
      "| Alexandria|   LA|    USA| AEX|\n",
      "|  Allentown|   PA|    USA| ABE|\n",
      "|   Alliance|   NE|    USA| AIA|\n",
      "|     Alpena|   MI|    USA| APN|\n",
      "|    Altoona|   PA|    USA| AOO|\n",
      "|   Amarillo|   TX|    USA| AMA|\n",
      "|Anahim Lake|   BC| Canada| YAA|\n",
      "|  Anchorage|   AK|    USA| ANC|\n",
      "|   Appleton|   WI|    USA| ATW|\n",
      "|     Arviat|  NWT| Canada| YEK|\n",
      "|  Asheville|   NC|    USA| AVL|\n",
      "|      Aspen|   CO|    USA| ASE|\n",
      "+-----------+-----+-------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-05T02:58:08.411786Z",
     "start_time": "2024-12-05T02:58:08.371911Z"
    }
   },
   "cell_type": "code",
   "source": [
    "rdd2.createOrReplaceTempView(\"departure\")\n",
    "rddTxt.createOrReplaceTempView(\"airport\")"
   ],
   "id": "82ecd96cee83ec9a",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-05T03:10:08.181305Z",
     "start_time": "2024-12-05T03:10:07.745320Z"
    }
   },
   "cell_type": "code",
   "source": "spark.sql(\"select * from airport inner join departure on airport.IATA=departure.origin where departure.origin = 'ATL' AND departure.destination = 'EWR' ORDER BY departure.delay\").show()",
   "id": "beb0e575df95493d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+-------+----+--------+-----+--------+------+-----------+\n",
      "|   City|State|Country|IATA|    date|delay|distance|origin|destination|\n",
      "+-------+-----+-------+----+--------+-----+--------+------+-----------+\n",
      "|Atlanta|   GA|    USA| ATL|02020848|   -1|     648|   ATL|        EWR|\n",
      "|Atlanta|   GA|    USA| ATL|03090848|   -1|     648|   ATL|        EWR|\n",
      "|Atlanta|   GA|    USA| ATL|01020730|   -1|     648|   ATL|        EWR|\n",
      "|Atlanta|   GA|    USA| ATL|03201115|   -1|     648|   ATL|        EWR|\n",
      "|Atlanta|   GA|    USA| ATL|02051237|   -1|     648|   ATL|        EWR|\n",
      "|Atlanta|   GA|    USA| ATL|03091345|   -1|     648|   ATL|        EWR|\n",
      "|Atlanta|   GA|    USA| ATL|01021500|   -1|     648|   ATL|        EWR|\n",
      "|Atlanta|   GA|    USA| ATL|03051345|   -1|     648|   ATL|        EWR|\n",
      "|Atlanta|   GA|    USA| ATL|02061350|   -1|     648|   ATL|        EWR|\n",
      "|Atlanta|   GA|    USA| ATL|03090742|   -1|     648|   ATL|        EWR|\n",
      "|Atlanta|   GA|    USA| ATL|01041920|   -1|     648|   ATL|        EWR|\n",
      "|Atlanta|   GA|    USA| ATL|03032140|   -1|     648|   ATL|        EWR|\n",
      "|Atlanta|   GA|    USA| ATL|02071919|   -1|     648|   ATL|        EWR|\n",
      "|Atlanta|   GA|    USA| ATL|03101236|   -1|     648|   ATL|        EWR|\n",
      "|Atlanta|   GA|    USA| ATL|01041630|   -1|     648|   ATL|        EWR|\n",
      "|Atlanta|   GA|    USA| ATL|03061236|   -1|     648|   ATL|        EWR|\n",
      "|Atlanta|   GA|    USA| ATL|02071000|   -1|     648|   ATL|        EWR|\n",
      "|Atlanta|   GA|    USA| ATL|03101345|   -1|     648|   ATL|        EWR|\n",
      "|Atlanta|   GA|    USA| ATL|01041120|   -1|     648|   ATL|        EWR|\n",
      "|Atlanta|   GA|    USA| ATL|03071915|   -1|     648|   ATL|        EWR|\n",
      "+-------+-----+-------+----+--------+-----+--------+------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "90f866cbf4fa78a4"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
